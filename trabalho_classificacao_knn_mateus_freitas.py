# -*- coding: utf-8 -*-
"""Trabalho - Classificacao KNN- Mateus Freitas

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KuMaHBJnLzjA_XQz1cI9CE0Fln9SXl2D

# Classificação KNN

O KNN é um dos algoritmos mais simples para Machine Learning, sendo um algoritmo do tipo "lazy", ou seja, nenhuma computação é realizada no dataset até que um novo ponto de dado seja alvo de teste.

criar um modelo preditivo usando KNN que, dadas as características do vinho, será capaz de classificar a qualidade do vinho, a partir do aprendizado obtido no treinamento do algoritmo

Classificação KNN em Python - Definindo Um Problema Para Classificação Multiclasse

## Importando Bibliotecas
"""

import numpy as np
from sklearn import datasets
from sklearn.metrics import confusion_matrix, plot_confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import csv

"""## Carregando e Explorando o Dataset"""

from google.colab import drive
drive.mount('/content/drive')

Wine_base_csv = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/winequality-red.csv', sep=";")
Wine_base_csv

Wine_base_csv.isnull()

# delete a single row by index value 0
Wine_base_csv = Wine_base_csv.drop(labels=500, axis=0)

# delete a single row by index value 0
Wine_base_csv = Wine_base_csv.drop(labels=400, axis=0)

plt.figure(figsize=(10, 10))
sns.heatmap(Wine_base_csv.isnull(),yticklabels=False,cbar=False,cmap='viridis')

"""## Pré-Processamento e Normalização"""

X_base = Wine_base_csv

y_base = X_base.pop("quality")

y_base

y_base.unique()

X_treino, X_teste, Y_treino, Y_teste = train_test_split(X_base, y_base, test_size = 0.30, random_state = 101)

treinoData, validData, treinoLabels, validLabels = train_test_split(X_treino, Y_treino, test_size = 0.1, random_state = 84)

print("Exemplos de Treino: {}".format(len(treinoLabels)))
print("Exemplos de Validação: {}".format(len(validLabels)))
print("Exemplos de Teste: {}".format(len(Y_teste)))

"""## Testando o Melhor Valor de K"""

kVals = range(1, 30, 2)

acuracias = []

# Loop em todos os valores de k para testar cada um deles

for k in kVals:
    
    # Treinando o modelo KNN com cada valor de k
    modeloKNN = KNeighborsClassifier(n_neighbors = k)
    modeloKNN.fit(X_treino, Y_treino)
          
    # Avaliando o modelo e atualizando a lista de acurácias
    acuracias.append(modeloKNN.score(X_teste, Y_teste))

plt.figure()
plt.xlabel("K count")
plt.ylabel("Model Accuracy")
plt.scatter(kVals, acuracias)
plt.grid()
plt.xticks([0, 5, 10, 15, 20, 30])
plt.show()

i = np.argmax(acuracias)
print("O valor de k = %d alcançou a mais alta acurácia de %.2f%% nos dados de validação!" % (kVals[i], acuracias[i] * 100))

"""## Construção e Treinamento do Modelo KNN"""

modeloFinal = KNeighborsClassifier(n_neighbors = kVals[i])

modeloFinal.fit(treinoData, treinoLabels)

"""## Previsões com Dados de Teste e Avaliação do Modelo"""

predictions = modeloFinal.predict(X_teste)

print("Avaliação do Modelo nos Dados de Teste")
print(classification_report(Y_teste, predictions))

cm = confusion_matrix(Y_teste, predictions)titles_options = [("Matriz de Confusão, sem normalização", None), ("Normalizada", 'true')]

for title, normalize in titles_options:
    disp = plot_confusion_matrix (modeloKNN, X_teste, Y_teste, cmap=plt.cm.Greens, normalize=normalize)
    disp.ax_.set_title(title)

    print(title)
    print(disp.confusion_matrix)

plt.show()

"""## Previsões em Novos Dados com o Modelo Treinado



"""

teste_size = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]


plt.figure()

for test_sizes in teste_size:
  scores = []

  for i in range(1, 1000):
    X_treino, X_teste, Y_treino, Y_teste = train_test_split(X_base, y_base, test_size = 1 - test_sizes)
    modeloKNN.fit(X_treino, Y_treino)
    scores.append(modeloKNN.score(X_teste, Y_teste))
  plt.plot(test_sizes, np.mean(scores))

plt.xlabel("Train Split %")
plt.ylabel("Accuracy")